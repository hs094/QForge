import { ProjectProfile, GeneratorOptions } from '../../types';
import { SelfHealingManager } from '../self-healing';
import YAML from 'yaml';

/**
 * Enhances a GitLab CI pipeline with additional features
 * @param pipelineContent Original pipeline content
 * @param projectProfile Project profile
 * @param options Generator options
 * @returns Enhanced pipeline content
 */
export function enhanceGitLabPipeline(
  pipelineContent: string,
  projectProfile: ProjectProfile,
  options: GeneratorOptions
): string {
  try {
    // Parse YAML content
    let pipeline: any;
    try {
      pipeline = YAML.parse(pipelineContent);
    } catch (error) {
      // If parsing fails, return the original content
      console.warn('Warning: Failed to parse GitLab CI YAML. Returning original content.');
      return pipelineContent;
    }

    // If pipeline is not valid, return the original content
    if (!pipeline) {
      return pipelineContent;
    }

    // Add a comment header
    const header = `# GitLab CI/CD pipeline generated by QForge
# Project languages: ${projectProfile.languages.join(', ')}
# Project frameworks: ${projectProfile.frameworks.join(', ')}
# Generated with options: ${JSON.stringify(options)}
`;

    // Ensure stages are defined
    if (!pipeline.stages) {
      pipeline.stages = ['build', 'test', 'deploy'];
    }

    // Add security scanning if requested
    if (options.security) {
      enhanceWithSecurity(pipeline, projectProfile);
    }

    // Add self-healing capabilities if requested
    if (options.selfHealing) {
      enhanceWithSelfHealing(pipeline);
    }

    // Convert back to YAML
    const enhancedContent = YAML.stringify(pipeline);

    // Return with header
    return header + enhancedContent;
  } catch (error) {
    // If any error occurs, return the original content
    console.warn(`Warning: Failed to enhance GitLab CI pipeline: ${error instanceof Error ? error.message : String(error)}`);
    return pipelineContent;
  }
}

/**
 * Enhances a pipeline with security scanning
 * @param pipeline Pipeline object
 * @param projectProfile Project profile
 */
function enhanceWithSecurity(pipeline: any, projectProfile: ProjectProfile): void {
  // Add security stage if not present
  if (!pipeline.stages.includes('security')) {
    const deployIndex = pipeline.stages.indexOf('deploy');
    if (deployIndex !== -1) {
      pipeline.stages.splice(deployIndex, 0, 'security');
    } else {
      pipeline.stages.push('security');
    }
  }

  // Add SAST job
  pipeline.sast = {
    stage: 'security',
    image: 'registry.gitlab.com/gitlab-org/security-products/sast:latest',
    variables: {
      SAST_EXCLUDED_PATHS: 'node_modules,dist,build,vendor',
      SCAN_KUBERNETES_MANIFESTS: 'false'
    },
    script: ['echo "Running SAST analysis..."'],
    artifacts: {
      reports: {
        sast: 'gl-sast-report.json'
      }
    },
    rules: [
      { when: 'always' }
    ],
    allow_failure: true
  };

  // Add dependency scanning for JavaScript/TypeScript projects
  if (projectProfile.languages.includes('JavaScript') || projectProfile.languages.includes('TypeScript')) {
    pipeline.dependency_scanning = {
      stage: 'security',
      image: 'registry.gitlab.com/gitlab-org/security-products/dependency-scanning:latest',
      script: ['echo "Running dependency scanning..."'],
      artifacts: {
        reports: {
          dependency_scanning: 'gl-dependency-scanning-report.json'
        }
      },
      rules: [
        { when: 'always' }
      ],
      allow_failure: true
    };
  }

  // Add container scanning if Docker is used
  if (projectProfile.hasDockerfile) {
    pipeline.container_scanning = {
      stage: 'security',
      image: 'registry.gitlab.com/gitlab-org/security-products/container-scanning:latest',
      variables: {
        CS_DEFAULT_BRANCH_IMAGE: '$CI_REGISTRY_IMAGE:latest'
      },
      script: ['echo "Running container scanning..."'],
      artifacts: {
        reports: {
          container_scanning: 'gl-container-scanning-report.json'
        }
      },
      rules: [
        { when: 'always' }
      ],
      allow_failure: true
    };
  }
}

/**
 * Interface for GitLab CI job configuration
 */
interface GitLabJob {
  retry?: {
    max: number;
    when: string[];
  };
  timeout?: string;
  artifacts?: {
    expire_in: string;
    paths?: string[];
    when?: string;
  };
  before_script?: string[];
  after_script?: string[];
  [key: string]: any;
}

/**
 * Enhances a pipeline with self-healing capabilities
 * @param pipeline Pipeline object
 */
function enhanceWithSelfHealing(pipeline: any): void {
  // Add retry to all jobs
  for (const [jobName, jobValue] of Object.entries(pipeline)) {
    if (typeof jobValue === 'object' && jobValue !== null && !['stages', 'variables', 'default', 'include'].includes(jobName)) {
      // Cast to GitLabJob type
      const job = jobValue as GitLabJob;

      // Add retry for flaky jobs
      if (!job.retry) {
        job.retry = {
          max: 2,
          when: ['runner_system_failure', 'script_failure', 'job_execution_timeout', 'api_failure', 'stuck_or_timeout_failure']
        };
      }

      // Add timeout to prevent hanging jobs
      if (!job.timeout) {
        job.timeout = '15m';
      }

      // Add artifacts expiration
      if (!job.artifacts) {
        job.artifacts = {
          expire_in: '1 week'
        };
      }

      // Add before_script to capture environment info
      if (!job.before_script) {
        job.before_script = [
          'echo "Running on $(uname -a)"',
          'echo "Available disk space: $(df -h .)"',
          'echo "Available memory: $(free -h)"'
        ];
      }

      // Add after_script to collect logs on failure
      if (!job.after_script) {
        job.after_script = [
          'mkdir -p logs',
          'find . -name "*.log" -exec cp {} logs/ \\; || true',
          'find . -name "*.out" -exec cp {} logs/ \\; || true',
          'find . -path "*/target/surefire-reports/*.xml" -exec cp {} logs/ \\; || true',
          'find . -path "*/build/test-results/*.xml" -exec cp {} logs/ \\; || true'
        ];
      }
    }
  }

  // Ensure we have a test stage
  if (!pipeline.stages || !pipeline.stages.includes('test')) {
    if (!pipeline.stages) {
      pipeline.stages = ['build', 'test', 'deploy'];
    } else if (Array.isArray(pipeline.stages)) {
      const deployIndex = pipeline.stages.indexOf('deploy');
      if (deployIndex !== -1) {
        pipeline.stages.splice(deployIndex, 0, 'test');
      } else {
        pipeline.stages.push('test');
      }
    }
  }

  // Add a job for analyzing failures
  pipeline.analyze_failures = {
    stage: 'test',
    image: 'alpine:latest',
    script: [
      'echo "Analyzing pipeline failures..."',
      'echo "Checking for common failure patterns:"',
      '',
      '# Check for test failures',
      'if grep -q "FAILED" logs/*.log 2>/dev/null; then',
      '  echo "✗ Test failures detected"',
      '  grep -A 5 -B 5 "FAILED" logs/*.log 2>/dev/null || true',
      'fi',
      '',
      '# Check for dependency issues',
      'if grep -q "Could not resolve dependencies" logs/*.log 2>/dev/null; then',
      '  echo "✗ Dependency resolution issues detected"',
      '  grep -A 5 -B 5 "Could not resolve dependencies" logs/*.log 2>/dev/null || true',
      'fi',
      '',
      '# Check for memory issues',
      'if grep -q "Out of memory" logs/*.log 2>/dev/null; then',
      '  echo "✗ Memory issues detected"',
      '  grep -A 5 -B 5 "Out of memory" logs/*.log 2>/dev/null || true',
      'fi',
      '',
      '# Check for permission issues',
      'if grep -q "Permission denied" logs/*.log 2>/dev/null; then',
      '  echo "✗ Permission issues detected"',
      '  grep -A 5 -B 5 "Permission denied" logs/*.log 2>/dev/null || true',
      'fi',
      '',
      '# Check for timeout issues',
      'if grep -q "timed out" logs/*.log 2>/dev/null; then',
      '  echo "✗ Timeout issues detected"',
      '  grep -A 5 -B 5 "timed out" logs/*.log 2>/dev/null || true',
      'fi',
      '',
      'echo "Analysis complete"'
    ],
    when: 'on_failure',
    allow_failure: true,
    artifacts: {
      paths: ['logs/'],
      expire_in: '1 week',
      when: 'on_failure'
    }
  };

  // Add a job for suggesting fixes
  pipeline.suggest_fixes = {
    stage: 'test',
    image: 'alpine:latest',
    script: [
      'echo "Suggested fixes based on analysis:"',
      '',
      '# Test failures',
      'echo "1. For test failures:"',
      'echo "   - Add retries for flaky tests"',
      'echo "   - Increase test timeouts"',
      'echo "   - Check for race conditions in tests"',
      'echo "   - Ensure test environment is properly set up"',
      '',
      '# Dependency issues',
      'echo "2. For dependency issues:"',
      'echo "   - Update dependencies to compatible versions"',
      'echo "   - Clear dependency caches"',
      'echo "   - Check for network issues when fetching dependencies"',
      'echo "   - Verify package repository access"',
      '',
      '# Resource issues',
      'echo "3. For resource constraints:"',
      'echo "   - Increase memory limits"',
      'echo "   - Optimize resource-intensive operations"',
      'echo "   - Split large jobs into smaller ones"',
      'echo "   - Use more powerful runners"',
      '',
      '# Permission issues',
      'echo "4. For permission issues:"',
      'echo "   - Check CI/CD variables and permissions"',
      'echo "   - Verify secrets are properly set"',
      'echo "   - Ensure file permissions are correct"',
      'echo "   - Check service account permissions"',
      '',
      '# Timeout issues',
      'echo "5. For timeout issues:"',
      'echo "   - Increase timeout limits"',
      'echo "   - Optimize slow operations"',
      'echo "   - Add progress reporting for long-running tasks"',
      'echo "   - Consider breaking up long-running jobs"',
      '',
      'echo "For more detailed analysis, run QForge locally with the --self-healing flag"',
      '',
      '# Create self-healing report',
      'cat > self-healing-report.md << EOL',
      '# Self-Healing Report',
      '',
      '## Failure Analysis',
      '',
      'The pipeline failed during execution. Here\'s an analysis of the potential issues:',
      '',
      '### Common Failure Patterns',
      '',
      '- **Test Failures**: Check test logs for assertion failures or errors',
      '- **Dependency Issues**: Verify all dependencies are correctly specified and accessible',
      '- **Resource Constraints**: Check if jobs are running out of memory or disk space',
      '- **Permission Problems**: Ensure the pipeline has the necessary permissions',
      '- **Configuration Errors**: Validate pipeline syntax and configuration',
      '',
      '### Recommended Actions',
      '',
      '1. **Review Recent Changes**: Look at recent commits that might have introduced the issue',
      '2. **Check Logs**: Examine the detailed logs for specific error messages',
      '3. **Verify Environment**: Ensure all CI/CD variables and secrets are properly set',
      '4. **Test Locally**: Try to reproduce and fix the issue in a local environment',
      '5. **Update Dependencies**: Make sure all dependencies are up to date',
      '',
      '## Self-Healing Capabilities',
      '',
      'This pipeline includes the following self-healing capabilities:',
      '',
      '- **Automatic Retries**: Flaky jobs will be automatically retried',
      '- **Failure Analysis**: Logs are analyzed to identify common failure patterns',
      '- **Suggested Fixes**: Based on the analysis, specific fixes are suggested',
      '- **Environment Diagnostics**: System information is captured for debugging',
      '- **Log Collection**: Logs are automatically collected for analysis',
      '',
      'For more advanced self-healing capabilities, run QForge locally with the --self-healing flag.',
      'EOL'
    ],
    when: 'on_failure',
    allow_failure: true,
    needs: ['analyze_failures'],
    artifacts: {
      paths: ['self-healing-report.md'],
      expire_in: '1 week',
      when: 'on_failure'
    }
  };

  // Add global variables for self-healing
  if (!pipeline.variables) {
    pipeline.variables = {};
  }

  pipeline.variables.GIT_STRATEGY = 'fetch';
  pipeline.variables.GIT_DEPTH = '50';
  pipeline.variables.ARTIFACT_COMPRESSION_LEVEL = 'fast';
  pipeline.variables.FF_USE_FASTZIP = 'true';
}
